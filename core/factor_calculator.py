"""
å› å­è®¡ç®—æ¨¡å—
æ•´åˆäº†å› å­é…ç½®ã€å› å­è®¡ç®—å’Œå› å­å­˜å‚¨åŠŸèƒ½
"""
import gc
import sys
import time
import traceback
from concurrent.futures import ProcessPoolExecutor
from typing import Dict, List, Union
from dataclasses import dataclass
from functools import cached_property
import re
import importlib

import numpy as np
import pandas as pd
from tqdm import tqdm

from core.utils.log_kit import logger
from pathlib import Path
import config

def get_col_name(factor_name, factor_param):
    """ç”Ÿæˆå› å­åˆ—å"""
    col_name = f"{factor_name}"
    if factor_param:  # å¦‚æœå‚æ•°æœ‰æ„ä¹‰çš„è¯æ‰æ˜¾ç¤ºå‡ºæ¥
        if isinstance(factor_param, (tuple, list)):
            factor_param_str = "(" + ",".join(map(str, factor_param)) + ")"
        else:
            factor_param_str = str(factor_param)
        col_name += f"_{factor_param_str}"
    return col_name


# ====================================================================================================
# ** å› å­é…ç½®ç›¸å…³ç±» **
# ====================================================================================================


# ====================================================================================================
# ** å› å­æ¥å£å’Œå› å­ä¸­å¿ƒ **
# ====================================================================================================
# å› å­æ¥å£ç±»å‹åˆ«åï¼Œç”¨äºç±»å‹æç¤º
FactorInterface = type('FactorInterface', (), {})


class FactorHub:
    _factor_cache = {}

    @staticmethod
    def get_by_name(factor_name):
        if factor_name in FactorHub._factor_cache:
            return FactorHub._factor_cache[factor_name]

        try:
            # æ„é€ æ¨¡å—å
            module_name = f"å› å­åº“.{factor_name}"

            # åŠ¨æ€å¯¼å…¥æ¨¡å—
            factor_module = importlib.import_module(module_name)

            # åˆ›å»ºä¸€ä¸ªåŒ…å«æ¨¡å—å˜é‡å’Œå‡½æ•°çš„å­—å…¸
            factor_content = {
                name: getattr(factor_module, name) for name in dir(factor_module)
                if not name.startswith("__")
            }

            if 'fin_cols' not in factor_content:
                factor_content['fin_cols'] = []

            # åˆ›å»ºä¸€ä¸ªåŒ…å«è¿™äº›å˜é‡å’Œå‡½æ•°çš„å¯¹è±¡
            factor_instance = type(factor_name, (), factor_content)

            # ç¼“å­˜ç­–ç•¥å¯¹è±¡
            FactorHub._factor_cache[factor_name] = factor_instance

            return factor_instance
        except ModuleNotFoundError:
            raise ValueError(f"Factor {factor_name} not found.")
        except AttributeError:
            raise ValueError(f"Error accessing factor content in module {factor_name}.")


# ====================================================================================================
# ** å› å­è®¡ç®—ç›¸å…³å¸¸é‡ **
# ====================================================================================================
# å› å­è®¡ç®—ä¹‹åï¼Œéœ€è¦ä¿å­˜çš„è¡Œæƒ…æ•°æ®
FACTOR_COLS = [
    "äº¤æ˜“æ—¥æœŸ",
    "è‚¡ç¥¨ä»£ç ",
    "è‚¡ç¥¨åç§°",
    "ä¸Šå¸‚è‡³ä»Šäº¤æ˜“å¤©æ•°",
    "å¤æƒå› å­",
    "å¼€ç›˜ä»·",
    "æœ€é«˜ä»·",
    "æœ€ä½ä»·",
    "æ”¶ç›˜ä»·",
    "æˆäº¤é¢",
    "æ˜¯å¦äº¤æ˜“",
    "æµé€šå¸‚å€¼",
    "æ€»å¸‚å€¼",
    "ä¸‹æ—¥_å¼€ç›˜æ¶¨åœ",
    "ä¸‹æ—¥_æ˜¯å¦ST",
    "ä¸‹æ—¥_æ˜¯å¦äº¤æ˜“",
    "ä¸‹æ—¥_æ˜¯å¦é€€å¸‚",
    "æ–°ç‰ˆç”³ä¸‡ä¸€çº§è¡Œä¸šåç§°"
]


# ====================================================================================================
# ** å› å­è®¡ç®—æ ¸å¿ƒå‡½æ•° **
# ====================================================================================================
def cal_strategy_factors(
    factor_params_dict: dict,
    stock_code: str,
    candle_df: pd.DataFrame,
    fin_data: Dict[str, pd.DataFrame] = None,
    factor_col_name_list: List[str] = (),
    start_date: str = None,
    end_date: str = None,
):
    """
    è®¡ç®—æŒ‡å®šè‚¡ç¥¨çš„ç­–ç•¥å› å­ã€‚

    å‚æ•°:
    factor_params_dict (dict): å› å­å‚æ•°å­—å…¸
    stock_code (str): è‚¡ç¥¨ä»£ç 
    candle_df (DataFrame): è‚¡ç¥¨çš„Kçº¿æ•°æ®ï¼Œå·²ç»æŒ‰ç…§"äº¤æ˜“æ—¥æœŸ"ä»å°åˆ°å¤§æ’åº
    fin_data (dict): è´¢åŠ¡æ•°æ®
    factor_col_name_list (list): éœ€è¦è®¡ç®—çš„å› å­åˆ—åç§°åˆ—è¡¨
    start_date (str): å¼€å§‹æ—¥æœŸ
    end_date (str): ç»“æŸæ—¥æœŸ

    è¿”å›:
    DataFrame: åŒ…å«è®¡ç®—å› å­çš„Kçº¿æ•°æ®
    """
    factor_series_dict = {}
    before_len = len(candle_df)

    candle_df.sort_values(by="äº¤æ˜“æ—¥æœŸ", inplace=True)  # é˜²æ­¢å› å­è®¡ç®—å‡ºé”™ï¼Œè®¡ç®—ä¹‹å‰ï¼Œå…ˆè¿›è¡Œæ’åº
    for factor_name, param_list in factor_params_dict.items():
        factor_file = FactorHub.get_by_name(factor_name)
        for param in param_list:
            col_name = get_col_name(factor_name, param)
            if col_name in factor_col_name_list:
                # å› å­è®¡ç®—ï¼Œfactor_dfæ˜¯åŒ…å«å› å­è®¡ç®—ç»“æœçš„DataFrameï¼Œå¿…é¡»æ˜¯æŒ‰ç…§"äº¤æ˜“æ—¥æœŸ"ä»å°åˆ°å¤§æ’åº
                factor_df = factor_file.add_factor(
                    candle_df.copy(),
                    param,
                    fin_data=fin_data,
                    col_name=col_name,
                )

                factor_series_dict[col_name] = factor_df[col_name].values
                # æ£€æŸ¥å› å­è®¡ç®—æ˜¯å¦å‡ºé”™
                if before_len != len(factor_series_dict[col_name]):
                    logger.error(
                        f"{stock_code}çš„{factor_name}å› å­({param}ï¼Œ{col_name})å¯¼è‡´æ•°æ®é•¿åº¦å‘ç”Ÿå˜åŒ–ï¼Œè¯·æ£€æŸ¥ï¼"
                    )
                    raise Exception("å› å­è®¡ç®—å‡ºé”™ï¼Œè¯·é¿å…åœ¨cal_factorsä¸­ä¿®æ”¹æ•°æ®è¡Œæ•°")

    kline_with_factor_dict = {**{col_name: candle_df[col_name] for col_name in FACTOR_COLS}, **factor_series_dict}
    kline_with_factor_df = pd.DataFrame(kline_with_factor_dict)
    kline_with_factor_df.sort_values(by="äº¤æ˜“æ—¥æœŸ", inplace=True)

    # æ ¹æ®å›æµ‹è®¾ç½®çš„æ—¶é—´åŒºé—´è¿›è¡Œè£åˆ‡
    start_date = start_date or kline_with_factor_df["äº¤æ˜“æ—¥æœŸ"].min()
    end_date = end_date or kline_with_factor_df["äº¤æ˜“æ—¥æœŸ"].max()
    date_cut_condition = (kline_with_factor_df["äº¤æ˜“æ—¥æœŸ"] >= start_date) & (
        kline_with_factor_df["äº¤æ˜“æ—¥æœŸ"] <= end_date
    )

    return kline_with_factor_df[date_cut_condition].reset_index(drop=True)  # è¿”å›è®¡ç®—å®Œçš„å› å­æ•°æ®


def process_by_stock(
    factor_params_dict: dict,
    candle_df: pd.DataFrame,
    factor_col_name_list: List[str],
    idx: int,
    fin_cols: List[str] = None,
    start_date: str = None,
    end_date: str = None,
):
    """
    ç»„è£…å› å­è®¡ç®—å¿…è¦çš„æ•°æ®ç»“æ„ï¼Œå¹¶ä¸”é€å…¥åˆ°å› å­è®¡ç®—å‡½æ•°ä¸­è¿›è¡Œè®¡ç®—
    :param factor_params_dict: å› å­å‚æ•°å­—å…¸
    :param candle_df: å•åªè‚¡ç¥¨çš„Kçº¿æ•°æ®
    :param factor_col_name_list: éœ€è¦è®¡ç®—çš„å› å­åˆ—åç§°åˆ—è¡¨
    :param idx: è‚¡ç¥¨ç´¢å¼•
    :param fin_cols: è´¢åŠ¡åˆ—åˆ—è¡¨
    :param start_date: å¼€å§‹æ—¥æœŸ
    :param end_date: ç»“æŸæ—¥æœŸ
    :return: idx, factor_df
    """
    stock_code = candle_df.iloc[-1]["è‚¡ç¥¨ä»£ç "]
    # å¯¼å…¥è´¢åŠ¡æ•°æ®ï¼Œå°†ä¸ªè‚¡æ•°æ®ä¸è´¢åŠ¡æ•°æ®åˆå¹¶ï¼Œå¹¶è®¡ç®—è´¢åŠ¡æŒ‡æ ‡çš„è¡ç”ŸæŒ‡æ ‡
    if fin_cols:  # å‰é¢å·²ç»åšäº†é¢„æ£€ï¼Œè¿™è¾¹åªéœ€è¦åŠ¨æ€åŠ è½½å³å¯
        # åˆ†åˆ«ä¸ºï¼šä¸ªè‚¡æ•°æ®ã€è´¢åŠ¡æ•°æ®ã€åŸå§‹è´¢åŠ¡æ•°æ®ï¼ˆä¸æŠ›å¼ƒåºŸå¼ƒçš„æŠ¥å‘Šæ•°æ®ï¼‰
        # ç®€åŒ–ç‰ˆæœ¬ï¼Œæš‚æ—¶è·³è¿‡è´¢åŠ¡æ•°æ®åˆå¹¶
        fin_data = None
    else:
        fin_data = None

    factor_df = cal_strategy_factors(
        factor_params_dict, stock_code, candle_df, fin_data, factor_col_name_list, start_date, end_date
    )

    return idx, factor_df


def calculate_factors(
    runtime_folder: str,
    factor_params_dict: dict,
    factor_col_name_list: List[str],
    fin_cols: List[str] = None,
    start_date: str = None,
    end_date: str = None,
):
    """
    è®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„å› å­ï¼ˆé»˜è®¤ä½¿ç”¨å¤šçº¿ç¨‹ï¼‰
    
    å‚æ•°:
    runtime_folder (str): è¿è¡Œæ—¶æ–‡ä»¶å¤¹è·¯å¾„
    factor_params_dict (dict): å› å­å‚æ•°å­—å…¸
    factor_col_name_list (list): éœ€è¦è®¡ç®—çš„å› å­åˆ—åç§°åˆ—è¡¨
    fin_cols (list): è´¢åŠ¡åˆ—åˆ—è¡¨
    start_date (str): å¼€å§‹æ—¥æœŸ
    end_date (str): ç»“æŸæ—¥æœŸ
    """
    logger.info("å› å­è®¡ç®—...")
    s_time = time.time()

    # 1. åŠ è½½è‚¡ç¥¨Kçº¿æ•°æ®
    logger.debug("ğŸ’¿ è¯»å–è‚¡ç¥¨Kçº¿æ•°æ®...")
    candle_df_dict: Dict[str, pd.DataFrame] = pd.read_pickle(Path(runtime_folder) / "è‚¡ç¥¨é¢„å¤„ç†æ•°æ®.pkl")

    # 2. è®¡ç®—å› å­å¹¶å­˜å‚¨ç»“æœ
    factor_col_count = len(factor_col_name_list)
    shards = range(0, factor_col_count, config.factor_col_limit)

    logger.debug(f"* æ€»å…±è®¡ç®—å› å­ä¸ªæ•°ï¼š{factor_col_count} ä¸ª")
    logger.debug(f"* å•æ¬¡è®¡ç®—å› å­ä¸ªæ•°ï¼š{config.factor_col_limit} ä¸ªï¼Œ(éœ€åˆ†æˆ{len(shards)}ç»„è®¡ç®—)")
    logger.debug(f"* éœ€è¦è®¡ç®—è‚¡ç¥¨æ•°é‡ï¼š{len(candle_df_dict.keys())} ä¸ª")
    logger.debug(f"ğŸš€ å¤šè¿›ç¨‹è®¡ç®—å› å­ï¼Œè¿›ç¨‹æ•°é‡ï¼š{config.n_jobs}")

    # æ¸…ç† cache çš„ç¼“å­˜
    all_kline_pkl = Path(runtime_folder) / "all_factors_kline.pkl"
    all_kline_pkl.unlink(missing_ok=True)

    logger.debug(f"ğŸš€ å¤šè¿›ç¨‹è®¡ç®—å› å­ï¼Œè¿›ç¨‹æ•°é‡ï¼š{config.n_jobs}" )
    for shard_index in shards:
        logger.debug(f"ğŸ—‚ï¸ å› å­åˆ†ç‰‡è®¡ç®—ä¸­ï¼Œè¿›åº¦ï¼š{int(shard_index / config.factor_col_limit) + 1}/{len(shards)}")
        factor_col_name_list_shard = factor_col_name_list[shard_index : shard_index + config.factor_col_limit]
        all_factor_df_list = [pd.DataFrame()] * len(candle_df_dict.keys())

        # ä½¿ç”¨å¤šè¿›ç¨‹è®¡ç®—å› å­
        with ProcessPoolExecutor(max_workers=config.n_jobs) as executor:
            futures = []
            for candle_idx, candle_df in enumerate(candle_df_dict.values()):
                futures.append(
                    executor.submit(
                        process_by_stock,
                        factor_params_dict,
                        candle_df,
                        factor_col_name_list_shard,
                        candle_idx,
                        fin_cols,
                        start_date,
                        end_date,
                    )
                )

            for future in tqdm(futures, desc="ğŸ§® è®¡ç®—å› å­", total=len(futures), mininterval=2, file=sys.stdout):
                try:
                    idx, period_df = future.result()
                    all_factor_df_list[idx] = period_df
                except Exception as e:
                    logger.error(f"å› å­è®¡ç®—å¤±è´¥ï¼š{e}")
                    logger.debug(traceback.format_exc())
                    raise e

        # 3. åˆå¹¶å› å­æ•°æ®å¹¶å­˜å‚¨
        all_factors_df = pd.concat(all_factor_df_list, ignore_index=True, copy=False)
        logger.debug("ğŸ“… å› å­ç»“æœæœ€æ™šæ—¥æœŸï¼š" + str(all_factors_df["äº¤æ˜“æ—¥æœŸ"].max()))

        # è½¬åŒ–ä¸€ä¸‹symbolçš„ç±»å‹ä¸ºcategoryï¼Œå¯ä»¥åŠ å¿«å› å­è®¡ç®—é€Ÿåº¦ï¼ŒèŠ‚çœå†…å­˜
        # å¹¶ä¸”æ’åºå’Œæ•´ç†index
        all_factors_df = (
            all_factors_df.assign(
                è‚¡ç¥¨ä»£ç =all_factors_df["è‚¡ç¥¨ä»£ç "].astype("category"),
                è‚¡ç¥¨åç§°=all_factors_df["è‚¡ç¥¨åç§°"].astype("category"),
            )
            .sort_values(by=["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ä»£ç "])
            .reset_index(drop=True)
        )

        logger.debug("ğŸ’¾ å­˜å‚¨å› å­æ•°æ®...")

        # å­˜å‚¨é€‰è‚¡éœ€è¦çš„kçº¿æ•°æ®
        if not all_kline_pkl.exists():
            all_kline_df = all_factors_df[FACTOR_COLS].sort_values(by=["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ä»£ç ", "è‚¡ç¥¨åç§°"])
            all_kline_df.to_pickle(all_kline_pkl)

        # å­˜å‚¨æ¯ä¸ªå› å­çš„æ•°æ®
        for factor_col_name in factor_col_name_list_shard:
            factor_pkl = Path(runtime_folder) / f"factor_{factor_col_name}.pkl"
            factor_pkl.unlink(missing_ok=True)
            all_factors_df[factor_col_name].to_pickle(factor_pkl)

        #å­˜å‚¨å¤§ä½œä¸šéœ€è¦çœ‹çš„dataframe
        if shard_index == 0:  # åªåœ¨ç¬¬ä¸€ä¸ªåˆ†ç‰‡æ—¶åˆ›å»ºä»»åŠ¡ä¸€df
            # é€‰æ‹©éœ€è¦çš„åˆ—
            required_cols = ["äº¤æ˜“æ—¥æœŸ", "è‚¡ç¥¨ä»£ç ", "è‚¡ç¥¨åç§°", "å¼€ç›˜ä»·", "æœ€é«˜ä»·", "æœ€ä½ä»·", "æ”¶ç›˜ä»·", "æ€»å¸‚å€¼"]
            task_df_cols = required_cols + factor_col_name_list_shard
            
            # åˆ›å»ºä»»åŠ¡ä¸€df
            task_df = all_factors_df[task_df_cols].copy()
            
            # è®¡ç®—æ¯ä¸ªå› å­çš„ç»Ÿè®¡ä¿¡æ¯
            factor_stats = {}
            for factor_col in factor_col_name_list_shard:
                if factor_col in task_df.columns:
                    factor_data = task_df[factor_col].dropna()
                    if len(factor_data) > 0:
                        factor_stats[factor_col] = {
                            'è®¡æ•°': len(factor_data),
                            'å¹³å‡å€¼': factor_data.mean(),
                            'æ ‡å‡†å·®': factor_data.std(),
                            'æœ€å°å€¼': factor_data.min(),
                            '20%åˆ†ä½æ•°': factor_data.quantile(0.2),
                            '50%åˆ†ä½æ•°': factor_data.quantile(0.5),
                            '75%åˆ†ä½æ•°': factor_data.quantile(0.75),
                            'æœ€å¤§å€¼': factor_data.max()
                        }
            
            # ä¿å­˜ä»»åŠ¡ä¸€df
            task_df_path = Path(runtime_folder) / "ä»»åŠ¡ä¸€df.pkl"
            task_df.to_pickle(task_df_path)
            logger.debug(f"ğŸ’¾ ä¿å­˜ä»»åŠ¡ä¸€dfåˆ°ï¼š{task_df_path}")
            
            # ä¿å­˜å› å­ç»Ÿè®¡ä¿¡æ¯
            factor_stats_df = pd.DataFrame(factor_stats).T
            factor_stats_path = Path(runtime_folder) / "å› å­ç»Ÿè®¡ä¿¡æ¯.csv"
            factor_stats_df.to_csv(factor_stats_path, encoding='utf-8-sig')
            logger.debug(f"ğŸ’¾ ä¿å­˜å› å­ç»Ÿè®¡ä¿¡æ¯åˆ°ï¼š{factor_stats_path}")
            
            # åˆ›å»ºå› å­ç»Ÿè®¡ä¿¡æ¯å¯è§†åŒ–
            try:
                import matplotlib.pyplot as plt
                import seaborn as sns
                plt.rcParams['font.sans-serif'] = ['SimHei']  # æ”¯æŒä¸­æ–‡æ˜¾ç¤º
                plt.rcParams['axes.unicode_minus'] = False  # æ”¯æŒè´Ÿå·æ˜¾ç¤º
                
                if factor_stats:
                    # è®¾ç½®å›¾å½¢å¤§å°
                    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
                    fig.suptitle('å› å­ç»Ÿè®¡ä¿¡æ¯å¯è§†åŒ–', fontsize=16, fontweight='bold')
                    
                    # 1. å› å­å¹³å‡å€¼å¯¹æ¯”æŸ±çŠ¶å›¾
                    factor_names = list(factor_stats.keys())[:min(8, len(factor_stats))]
                    mean_values = [factor_stats[name]['å¹³å‡å€¼'] for name in factor_names]
                    axes[0, 0].bar(range(len(factor_names)), mean_values, alpha=0.7, edgecolor='black')
                    axes[0, 0].set_title('å› å­å¹³å‡å€¼å¯¹æ¯”')
                    axes[0, 0].set_xlabel('å› å­åç§°')
                    axes[0, 0].set_ylabel('å¹³å‡å€¼')
                    axes[0, 0].set_xticks(range(len(factor_names)))
                    axes[0, 0].set_xticklabels(factor_names, rotation=45)
                    
                    # 2. å› å­æ ‡å‡†å·®å¯¹æ¯”æŸ±çŠ¶å›¾
                    std_values = [factor_stats[name]['æ ‡å‡†å·®'] for name in factor_names]
                    axes[0, 1].bar(range(len(factor_names)), std_values, alpha=0.7, edgecolor='black', color='orange')
                    axes[0, 1].set_title('å› å­æ ‡å‡†å·®å¯¹æ¯”')
                    axes[0, 1].set_xlabel('å› å­åç§°')
                    axes[0, 1].set_ylabel('æ ‡å‡†å·®')
                    axes[0, 1].set_xticks(range(len(factor_names)))
                    axes[0, 1].set_xticklabels(factor_names, rotation=45)
                    
                    # 3. å› å­ç›¸å…³æ€§çƒ­åŠ›å›¾ï¼ˆé€‰æ‹©å‰å‡ ä¸ªå› å­ï¼‰
                    if len(factor_col_name_list_shard) > 1:
                        factor_corr_data = task_df[factor_col_name_list_shard[:min(10, len(factor_col_name_list_shard))]].corr()
                        sns.heatmap(factor_corr_data, annot=True, cmap='coolwarm', center=0, ax=axes[1, 0])
                        axes[1, 0].set_title('å› å­ç›¸å…³æ€§çƒ­åŠ›å›¾')
                    else:
                        axes[1, 0].text(0.5, 0.5, 'å› å­æ•°é‡ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆç›¸å…³æ€§çƒ­åŠ›å›¾', 
                                       ha='center', va='center', transform=axes[1, 0].transAxes)
                        axes[1, 0].set_title('å› å­ç›¸å…³æ€§çƒ­åŠ›å›¾')
                    
                    # 4. å› å­åˆ†å¸ƒç®±çº¿å›¾ï¼ˆé€‰æ‹©å‰å‡ ä¸ªå› å­ï¼‰
                    if len(factor_col_name_list_shard) > 0:
                        factor_data_for_box = []
                        factor_labels = []
                        for factor_col in factor_col_name_list_shard[:min(6, len(factor_col_name_list_shard))]:
                            if factor_col in task_df.columns:
                                factor_data = task_df[factor_col].dropna()
                                if len(factor_data) > 0:
                                    factor_data_for_box.append(factor_data)
                                    factor_labels.append(factor_col)
                        
                        if factor_data_for_box:
                            axes[1, 1].boxplot(factor_data_for_box, labels=factor_labels)
                            axes[1, 1].set_title('å› å­åˆ†å¸ƒç®±çº¿å›¾')
                            axes[1, 1].set_xlabel('å› å­åç§°')
                            axes[1, 1].set_ylabel('å› å­å€¼')
                            axes[1, 1].tick_params(axis='x', rotation=45)
                        else:
                            axes[1, 1].text(0.5, 0.5, 'æ— æœ‰æ•ˆå› å­æ•°æ®', ha='center', va='center', transform=axes[1, 1].transAxes)
                            axes[1, 1].set_title('å› å­åˆ†å¸ƒç®±çº¿å›¾')
                    else:
                        axes[1, 1].text(0.5, 0.5, 'æ— å› å­æ•°æ®', ha='center', va='center', transform=axes[1, 1].transAxes)
                        axes[1, 1].set_title('å› å­åˆ†å¸ƒç®±çº¿å›¾')
                    
                    plt.tight_layout()
                    
                    # ä¿å­˜å›¾ç‰‡
                    visualization_path = Path(runtime_folder) / "ä»»åŠ¡ä¸€dfå¯è§†åŒ–.png"
                    plt.savefig(visualization_path, dpi=300, bbox_inches='tight')
                    plt.close()
                    logger.debug(f"ğŸ’¾ ä¿å­˜å› å­ç»Ÿè®¡ä¿¡æ¯å¯è§†åŒ–å›¾ç‰‡åˆ°ï¼š{visualization_path}")
                else:
                    logger.warning("æ— å› å­ç»Ÿè®¡ä¿¡æ¯ï¼Œè·³è¿‡å¯è§†åŒ–ç”Ÿæˆ")
                
            except ImportError:
                logger.warning("matplotlibæˆ–seabornæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–ç”Ÿæˆ")
            except Exception as e:
                logger.warning(f"å¯è§†åŒ–ç”Ÿæˆå¤±è´¥ï¼š{e}")

        gc.collect()

    logger.ok(f"å› å­è®¡ç®—å®Œæˆï¼Œè€—æ—¶ï¼š{time.time() - s_time:.2f}ç§’")
